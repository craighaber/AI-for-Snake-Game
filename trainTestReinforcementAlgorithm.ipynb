{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "739c2fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import gym\n",
    "import gym_snake\n",
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3.common.logger import configure\n",
    "import numpy as np\n",
    "from argparse import ArgumentParser\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdb19e1",
   "metadata": {},
   "source": [
    "# Read This First\n",
    "This notebook is created to make it clear how we train and test the OpenAI Gym Snake. I used jupytext so that it can be run on the server as a python commandline script or as a jupyter notebook on your local machine. If you are just seeing the python file (and not the .ipynb file) locally, then you probably need to [install jupytext](https://jupytext.readthedocs.io/_/downloads/en/stable/pdf/):\n",
    "```\n",
    "pip install jupytext\n",
    "# or\n",
    "conda install jupytext -c conda-forge \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfd28b0",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "577427ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainRL(\n",
    "    train_timesteps= 1000,  # Number of steps to train the snake on. One step is one action for snake.\n",
    "    env_name='snake-v0',\n",
    "):\n",
    "    env = gym.make(env_name, use_pygame=False)  # We don't want to visualize the training process\n",
    "    \n",
    "    # Model is defined here. This is hard to parameterize so change this code to play with different models\n",
    "    model = A2C('MlpPolicy', env, verbose=1)    \n",
    "    \n",
    "    t0 = time.time()\n",
    "    model.learn(\n",
    "        total_timesteps=train_timesteps  # Number of actions the model should take in learning\n",
    "    )\n",
    "    t1 = time.time()\n",
    "    print(\"Finished training in \" + str(round(t1-t0, 2)) + \" seconds\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10445424",
   "metadata": {},
   "source": [
    "## Test\n",
    "Test the model to see how well it is performing. Also have the option to visualize the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67eaa25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testRL(\n",
    "    model,\n",
    "    test_timesteps=1000,  # Number of steps to test the snake on. One step is one action for snake.\n",
    "    env_name='snake-v0',\n",
    "    visualize_testing= True,  # Set to true in order to see game moves in pygame. Should be false if run on server.\n",
    "):\n",
    "    # Setup\n",
    "    env = gym.make(\n",
    "        'snake-v0',\n",
    "        use_pygame=visualize_testing\n",
    "    )\n",
    "    obs = env.reset()\n",
    "    \n",
    "    # Run\n",
    "    scores = []\n",
    "    for i in range(test_timesteps):\n",
    "        action, _state = model.predict(obs, deterministic=True)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        if done:\n",
    "            scores.append(env.game.score)\n",
    "            obs = env.reset()\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22801dd",
   "metadata": {},
   "source": [
    "## Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4e6e367",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyzeRL(\n",
    "    scores,  # array of scores for each completed game\n",
    "):\n",
    "    s_arr = np.array(scores)\n",
    "    print(\"Number of completed games: \", len(s_arr))\n",
    "\n",
    "    if len(s_arr) > 0:\n",
    "        print(\"High Score over all games: \", np.max(s_arr))\n",
    "        print(\"Mean Score over all games: \", np.average(s_arr))\n",
    "        print(\"Median Score over all games: \", np.average(s_arr))    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0d707c",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9750422b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveRL(\n",
    "    model, \n",
    "    model_filename=\"\"  # Filename to save model under. If empty, defaults to naming using datetime\n",
    "):\n",
    "    \n",
    "    if len(model_filename) == 0:\n",
    "        model_filename = \"saved_models/\"+str(datetime.now().strftime(\"[%Y-%m-%d %H:%M:%S%z]\"))\n",
    "    \n",
    "    model.save(model_filename)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166729d4",
   "metadata": {},
   "source": [
    "## Run in Notebook\n",
    "To run in the notebook, uncomment the following three lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b029c56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = trainRL()\n",
    "# scores = testRL(model)\n",
    "# analyzeRL(scores)\n",
    "# saveRL(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222d4748",
   "metadata": {},
   "source": [
    "## Run on commandline\n",
    "Note that it is expected that this does not work in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdf875e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Get arguments\n",
    "    aparser = ArgumentParser(\"Snnake Reinforcement Learning\")\n",
    "    aparser.add_argument(\"--env_name\", type=str, default=\"snake-v0\")\n",
    "\n",
    "    aparser.add_argument(\"--train_timesteps\", type=int, default=1000)\n",
    "    \n",
    "    aparser.add_argument(\"--test_timesteps\", type=int, default=100)\n",
    "    aparser.add_argument(\"--visualize_testing\", type=bool, default=True)\n",
    "    \n",
    "    aparser.add_argument(\"--print_analysis\", type=bool, default=True, help=\"bool to determine whether or not analysis of test scores is done\")    \n",
    "    \n",
    "    aparser.add_argument(\"--save_model\", type=bool, default=False, help=\"bool to determine whether or not to save the trained model\")        \n",
    "    aparser.add_argument(\"--model_filename\", type=str, default=\"\", help=\"filename for model if it is saved. Should probably start with 'saved_models/' directory\")        \n",
    "    \n",
    "    args = aparser.parse_args()\n",
    "    \n",
    "    # Training\n",
    "    model = trainRL(args.train_timesteps, args.env_name)\n",
    "    \n",
    "    # Testing\n",
    "    scores = testRL(model, args.test_timesteps, args.env_name, args.visualize_testing)\n",
    "    \n",
    "    # Analysis\n",
    "    if args.print_analysis:\n",
    "        analyzeRL(scores)\n",
    "        \n",
    "    # Save\n",
    "    if args.save_model:\n",
    "        saveRL(model, args.model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1f3ab93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: Snnake Reinforcement Learning [-h] [--env_name ENV_NAME]\n",
      "                                     [--train_timesteps TRAIN_TIMESTEPS]\n",
      "                                     [--test_timesteps TEST_TIMESTEPS]\n",
      "                                     [--visualize_testing VISUALIZE_TESTING]\n",
      "                                     [--print_analysis PRINT_ANALYSIS]\n",
      "                                     [--save_model SAVE_MODEL]\n",
      "                                     [--model_filename MODEL_FILENAME]\n",
      "Snnake Reinforcement Learning: error: unrecognized arguments: -f /Users/jackdavidweber/Library/Jupyter/runtime/kernel-0e4a8ced-3a5e-487b-8b94-8c923187abcb.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/aiGym/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3452: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
